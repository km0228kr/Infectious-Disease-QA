{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ratsnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kobert-transformers\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ratsnlp.nlpbook.qa import QATrainArguments\n",
    "from transformers import BertConfig, BertForQuestionAnswering\n",
    "from kobert_transformers import get_tokenizer\n",
    "from ratsnlp import nlpbook\n",
    "from ratsnlp.nlpbook.qa import KorQuADV1Corpus, QADataset, QATask\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 (평가제외)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from ratsnlp.nlpbook.qa import QATrainArguments\n",
    "from transformers import BertConfig, BertForQuestionAnswering\n",
    "from kobert_transformers import get_tokenizer\n",
    "from ratsnlp import nlpbook\n",
    "from ratsnlp.nlpbook.qa import KorQuADV1Corpus, QADataset, QATask\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# CUDA 메모리 설정\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "\n",
    "# Arguments 설정\n",
    "args = QATrainArguments(\n",
    "    pretrained_model_name=\"skt/kobert-base-v1\",\n",
    "    downstream_corpus_name=\"korquad-v1\",\n",
    "    downstream_model_dir=\"/home/km0228kr/KoBERT/model/model1285e64\",\n",
    "    max_seq_length=128,\n",
    "    max_query_length=64,\n",
    "    doc_stride=64,\n",
    "    batch_size=16,  # 복수 GPU를 사용하므로 배치 크기를 늘림\n",
    "    learning_rate=5e-5,  # learning rate 유지\n",
    "    epochs=3,\n",
    "    tpu_cores=0 if torch.cuda.is_available() else 8,\n",
    "    seed=7,\n",
    "    downstream_corpus_root_dir=\"/home/km0228kr/Korpora\"  # 다운로드 경로 수정\n",
    ")\n",
    "\n",
    "# Add this line to set the device\n",
    "args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# KoBERT 전용 토크나이저 사용\n",
    "tokenizer = get_tokenizer()\n",
    "\n",
    "# 모델 설정\n",
    "pretrained_model_config = BertConfig.from_pretrained(\"skt/kobert-base-v1\")\n",
    "model = BertForQuestionAnswering.from_pretrained(\"skt/kobert-base-v1\", config=pretrained_model_config)\n",
    "model.to(args.device)\n",
    "\n",
    "# 시드 설정 및 로깅\n",
    "nlpbook.set_seed(args)\n",
    "nlpbook.set_logger(args)\n",
    "\n",
    "# 다운로드 경로 수정\n",
    "os.makedirs(args.downstream_corpus_root_dir, exist_ok=True)\n",
    "\n",
    "nlpbook.download_downstream_dataset(args)\n",
    "\n",
    "# 데이터셋 준비\n",
    "corpus = KorQuADV1Corpus()\n",
    "train_dataset = QADataset(args=args, corpus=corpus, tokenizer=tokenizer, mode=\"train\")\n",
    "val_dataset = QADataset(args=args, corpus=corpus, tokenizer=tokenizer, mode=\"val\")\n",
    "\n",
    "# 데이터로더 설정\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    sampler=RandomSampler(train_dataset, replacement=False),\n",
    "    collate_fn=nlpbook.data_collator,\n",
    "    drop_last=False,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    sampler=SequentialSampler(val_dataset),\n",
    "    collate_fn=nlpbook.data_collator,\n",
    "    drop_last=False,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "# 학습 태스크 설정\n",
    "task = QATask(model, args)\n",
    "\n",
    "# 트레이너 설정 (복수 GPU 사용)\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=args.downstream_model_dir,\n",
    "    save_top_k=1,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    filename='{epoch}-{val_loss:.2f}'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=args.epochs,\n",
    "    strategy='dp',  # 분산 학습 전략을 dp로 설정\n",
    "    gpus=torch.cuda.device_count(),  # 사용 가능한 모든 GPU 사용\n",
    "    callbacks=[checkpoint_callback],\n",
    "    progress_bar_refresh_rate=20\n",
    ")\n",
    "\n",
    "# 학습\n",
    "trainer.fit(task, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "\n",
    "# 모델 저장\n",
    "os.makedirs(args.downstream_model_dir, exist_ok=True)\n",
    "model_path = os.path.join(args.downstream_model_dir, \"pytorch_model.bin\")\n",
    "torch.save(model.state_dict(), model_path)\n",
    "vocab_path = os.path.join(args.downstream_model_dir, \"vocab.txt\")\n",
    "tokenizer.save_vocabulary(args.downstream_model_dir)\n",
    "config_path = os.path.join(args.downstream_model_dir, \"config.json\")\n",
    "pretrained_model_config.save_pretrained(args.downstream_model_dir)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")\n",
    "print(f\"Tokenizer vocabulary saved to {vocab_path}\")\n",
    "print(f\"Config saved to {config_path}\")\n",
    "\n",
    "# 평가 함수\n",
    "def evaluate_model(model, dataloader, tokenizer):\n",
    "    model.eval()\n",
    "    pred_answers = []\n",
    "    true_answers = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        inputs = {\n",
    "            \"input_ids\": batch[\"input_ids\"].to(args.device),\n",
    "            \"attention_mask\": batch[\"attention_mask\"].to(args.device),\n",
    "            \"token_type_ids\": batch[\"token_type_ids\"].to(args.device),\n",
    "        }\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        start_logits = outputs.start_logits.detach().cpu().numpy()\n",
    "        end_logits = outputs.end_logits.detach().cpu().numpy()\n",
    "\n",
    "        for i in range(start_logits.shape[0]):\n",
    "            start_idx = np.argmax(start_logits[i])\n",
    "            end_idx = np.argmax(end_logits[i])\n",
    "            pred_answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(batch[\"input_ids\"][i][start_idx:end_idx+1]))\n",
    "            true_answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(batch[\"input_ids\"][i][batch[\"start_positions\"][i]:batch[\"end_positions\"][i]+1]))\n",
    "            pred_answers.append(pred_answer)\n",
    "            true_answers.append(true_answer)\n",
    "\n",
    "    return pred_answers, true_answers\n",
    "\n",
    "# F1 Score, Accuracy, Exact Match 계산\n",
    "def calculate_metrics(pred_answers, true_answers):\n",
    "    f1 = f1_score(true_answers, pred_answers, average='macro')\n",
    "    accuracy = accuracy_score(true_answers, pred_answers)\n",
    "    exact_match = sum([1 if pred == true else 0 for pred, true in zip(pred_answers, true_answers)]) / len(true_answers)\n",
    "    return f1, accuracy, exact_match\n",
    "\n",
    "'''# 모델 평가\n",
    "pred_answers, true_answers = evaluate_model(model, val_dataloader, tokenizer)\n",
    "f1, accuracy, exact_match = calculate_metrics(pred_answers, true_answers)\n",
    "\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Exact Match: {exact_match}\")'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "평가용\n",
    "\"/content/drive/MyDrive/공모전/kobert_323e\"\n",
    "32\n",
    "3e-5\n",
    "'''\n",
    "import torch\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from kobert_transformers import get_tokenizer\n",
    "import numpy as np\n",
    "from ratsnlp.nlpbook.qa import QATrainArguments\n",
    "from transformers import BertForQuestionAnswering\n",
    "from ratsnlp import nlpbook\n",
    "from ratsnlp.nlpbook.qa import KorQuADV1Corpus, QADataset\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "\n",
    "# 학습 파라미터 설정\n",
    "args = QATrainArguments(\n",
    "    pretrained_model_name=\"skt/kobert-base-v1\",\n",
    "    downstream_corpus_name=\"korquad-v1\",\n",
    "    downstream_model_dir=\"/home/km0228kr/KoBERT/model/model1285e64\",\n",
    "    max_seq_length=128,\n",
    "    max_query_length=64,\n",
    "    doc_stride=64,\n",
    "    batch_size=16,  # 배치 크기 설정\n",
    "    learning_rate=5e-5,  # 학습률 설정\n",
    "    epochs=3,\n",
    "    tpu_cores=0 if torch.cuda.is_available() else 8,\n",
    "    seed=7,\n",
    "    downstream_corpus_root_dir=\"./Korpora\"  # 변경된 경로\n",
    ")\n",
    "\n",
    "# 모델 불러오기\n",
    "model_path = \"/home/km0228kr/KoBERT/model/model1285e64/pytorch_model.bin\"\n",
    "model = BertForQuestionAnswering.from_pretrained(\"skt/kobert-base-v1\")\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")))\n",
    "\n",
    "# 디바이스 설정 (GPU 사용 가능 시 GPU 사용)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# KoBERT 전용 토크나이저 사용\n",
    "tokenizer = get_tokenizer()\n",
    "\n",
    "# 평가 함수 정의\n",
    "def evaluate_model(model, dataloader, tokenizer):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    pred_answers = []\n",
    "    true_answers = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        inputs = {\n",
    "            \"input_ids\": batch[\"input_ids\"].to(device),\n",
    "            \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
    "            \"token_type_ids\": batch[\"token_type_ids\"].to(device),\n",
    "        }\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        start_logits = outputs.start_logits.detach().cpu().numpy()\n",
    "        end_logits = outputs.end_logits.detach().cpu().numpy()\n",
    "\n",
    "        for i in range(start_logits.shape[0]):\n",
    "            start_idx = np.argmax(start_logits[i])\n",
    "            end_idx = np.argmax(end_logits[i])\n",
    "            pred_answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(batch[\"input_ids\"][i][start_idx:end_idx+1]))\n",
    "            true_answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(batch[\"input_ids\"][i][batch[\"start_positions\"][i]:batch[\"end_positions\"][i]+1]))\n",
    "            pred_answers.append(pred_answer)\n",
    "            true_answers.append(true_answer)\n",
    "\n",
    "    return pred_answers, true_answers\n",
    "\n",
    "# F1 Score, Accuracy, Exact Match 계산 함수 정의\n",
    "def calculate_metrics(pred_answers, true_answers):\n",
    "    f1 = f1_score(true_answers, pred_answers, average='macro')\n",
    "    accuracy = accuracy_score(true_answers, pred_answers)\n",
    "    exact_match = sum([1 if pred == true else 0 for pred, true in zip(pred_answers, true_answers)]) / len(true_answers)\n",
    "    return f1, accuracy, exact_match\n",
    "\n",
    "# 시드 설정 및 로깅\n",
    "nlpbook.set_seed(args)\n",
    "nlpbook.set_logger(args)\n",
    "\n",
    "# 다운로드 경로 수정\n",
    "os.makedirs(args.downstream_corpus_root_dir, exist_ok=True)\n",
    "\n",
    "nlpbook.download_downstream_dataset(args)\n",
    "\n",
    "# 데이터셋 준비\n",
    "corpus = KorQuADV1Corpus()\n",
    "train_dataset = QADataset(args=args, corpus=corpus, tokenizer=tokenizer, mode=\"train\")\n",
    "val_dataset = QADataset(args=args, corpus=corpus, tokenizer=tokenizer, mode=\"val\")\n",
    "\n",
    "# 데이터로더 설정 (val_dataloader를 올바르게 설정)\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    sampler=SequentialSampler(val_dataset),\n",
    "    collate_fn=nlpbook.data_collator,\n",
    "    drop_last=False,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "# 모델 평가\n",
    "pred_answers, true_answers = evaluate_model(model, val_dataloader, tokenizer)\n",
    "f1, accuracy, exact_match = calculate_metrics(pred_answers, true_answers)\n",
    "\n",
    "print(f\"F1 점수: {f1}\")\n",
    "print(f\"정확도: {accuracy}\")\n",
    "print(f\"정확 일치: {exact_match}\")\n",
    "import json\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "from kobert_transformers import get_tokenizer\n",
    "import numpy as np\n",
    "from ratsnlp.nlpbook.qa import QATrainArguments\n",
    "from transformers import BertForQuestionAnswering\n",
    "from ratsnlp.nlpbook.qa import KorQuADV1Corpus, QADataset\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "import os\n",
    "\n",
    "# 평가에 필요한 파라미터 설정\n",
    "args = QATrainArguments(\n",
    "    pretrained_model_name=\"skt/kobert-base-v1\",\n",
    "    downstream_corpus_name=\"korquad-v1\",\n",
    "    downstream_model_dir=\"/home/km0228kr/KoBERT/model/model1282e\",\n",
    "    max_seq_length=128,\n",
    "    max_query_length=64,\n",
    "    doc_stride=128,\n",
    "    batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    epochs=3,\n",
    "    tpu_cores=0 if torch.cuda.is_available() else 8,\n",
    "    seed=7,\n",
    "    downstream_corpus_root_dir=\"./Korpora\"\n",
    ")\n",
    "\n",
    "# 모델 불러오기\n",
    "model_path = \"/home/km0228kr/KoBERT/model/model1282e/pytorch_model.bin\"\n",
    "model = BertForQuestionAnswering.from_pretrained(\"skt/kobert-base-v1\")\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")))\n",
    "\n",
    "# 디바이스 설정 (GPU 사용 가능 시 GPU 사용)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# KoBERT 전용 토크나이저 사용\n",
    "tokenizer = get_tokenizer()\n",
    "\n",
    "# 데이터셋 준비\n",
    "corpus = KorQuADV1Corpus()\n",
    "train_dataset = QADataset(args=args, corpus=corpus, tokenizer=tokenizer, mode=\"train\")\n",
    "val_dataset = QADataset(args=args, corpus=corpus, tokenizer=tokenizer, mode=\"val\")\n",
    "\n",
    "# 데이터로더 설정 (val_dataloader를 올바르게 설정)\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    sampler=SequentialSampler(val_dataset),\n",
    "    collate_fn=nlpbook.data_collator,\n",
    "    drop_last=False,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "# 평가 함수\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "        start_positions = batch[\"start_positions\"].to(device)\n",
    "        end_positions = batch[\"end_positions\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "            start_logits = outputs.start_logits\n",
    "            end_logits = outputs.end_logits\n",
    "\n",
    "        start_preds = torch.argmax(start_logits, dim=-1)\n",
    "        end_preds = torch.argmax(end_logits, dim=-1)\n",
    "\n",
    "        for i in range(len(start_positions)):\n",
    "            all_predictions.append((start_preds[i].item(), end_preds[i].item()))\n",
    "            all_true_labels.append((start_positions[i].item(), end_positions[i].item()))\n",
    "\n",
    "    # EM 및 F1 스코어 계산\n",
    "    exact_matches = 0\n",
    "    f1_total = 0\n",
    "\n",
    "    for pred, true in zip(all_predictions, all_true_labels):\n",
    "        pred_start, pred_end = pred\n",
    "        true_start, true_end = true\n",
    "\n",
    "        if pred_start == true_start and pred_end == true_end:\n",
    "            exact_matches += 1\n",
    "\n",
    "        pred_tokens = set(range(pred_start, pred_end + 1))\n",
    "        true_tokens = set(range(true_start, true_end + 1))\n",
    "\n",
    "        common_tokens = pred_tokens.intersection(true_tokens)\n",
    "\n",
    "        if len(common_tokens) == 0:\n",
    "            f1_total += 0\n",
    "        else:\n",
    "            precision = len(common_tokens) / len(pred_tokens)\n",
    "            recall = len(common_tokens) / len(true_tokens)\n",
    "            f1_total += 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    exact_match_score = exact_matches / len(all_true_labels)\n",
    "    f1_score = f1_total / len(all_true_labels)\n",
    "\n",
    "    print(f\"Exact Match (EM): {exact_match_score}\")\n",
    "    print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "# 평가 실행\n",
    "evaluate(model, val_dataloader, device)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
